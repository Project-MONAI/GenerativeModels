{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4a1d6c",
   "metadata": {},
   "source": [
    "# 3D AutoencoderKL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca65c39",
   "metadata": {},
   "source": [
    "This demo is a toy example of how to use MONAI's AutoencoderKL. In particular, it uses the Autoencoder with a Kullback-Leibler regularisation as implemented by Rombach et. al [1].\n",
    "\n",
    "[1] Rombach et. al - [\"High-Resolution Image Synthesis with Latent Diffusion Models\"](https://arxiv.org/pdf/2112.10752.pdf)\n",
    "\n",
    "This tutorial was based on:\n",
    "\n",
    "[Brain tumor 3D segmentation with MONAI](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/brats_segmentation_3d.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946adc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add Open in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[pillow, tqdm, einops, nibabel]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0964dd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt_homes/home4T7/jdafflon/GenerativeModels\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt_homes/home4T7/jdafflon/GenerativeModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325d9ae",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a44e7a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdafflon/miniconda3/envs/genmodels/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.1.dev2239\n",
      "Numpy version: 1.23.4\n",
      "Pytorch version: 1.13.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 13b24fa92b9d98bd0dc6d5cdcb52504fd09e297b\n",
      "MONAI __file__: /home/jdafflon/miniconda3/envs/genmodels/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.14.0\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.4\n",
      "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "einops version: 0.6.0\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader\n",
    "from monai.networks.layers import Act\n",
    "from monai.utils import first, set_determinism\n",
    "from torch.cuda.amp import autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generative.losses.adversarial_loss import PatchAdversarialLoss\n",
    "from generative.losses.perceptual import PerceptualLoss\n",
    "from generative.networks.nets import AutoencoderKL, PatchDiscriminator\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aaa77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility purposes set a seed\n",
    "set_determinism(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bae2d5",
   "metadata": {},
   "source": [
    "## Setup a data directory and download dataset\n",
    "\n",
    "Specify a `MONAI_DATA_DIRECTORY` variable, where the data will be downloaded. If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48155dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpyxyg6wxs\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "root_dir = \"/tmp/tmpyxyg6wxs\"\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bff04",
   "metadata": {},
   "source": [
    "## Download the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fdee1",
   "metadata": {},
   "source": [
    "Note: The DecatholonDataset has 7GB. So make sure that you have enought space when running the next line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbaf6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  51%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 198/388 [01:21<01:02,  3.04it/s]"
     ]
    }
   ],
   "source": [
    "channel = 0  # 0 = Flair\n",
    "assert channel in [0, 1, 2, 3], \"Choose a valid channel\"\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.Lambdad(keys=\"image\", func=lambda x: x[channel, :, :, :]),\n",
    "        transforms.AddChanneld(keys=[\"image\"]),\n",
    "        transforms.EnsureTyped(keys=[\"image\"]),\n",
    "        transforms.Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        transforms.Spacingd(\n",
    "            keys=[\"image\"],\n",
    "            pixdim=(2.4, 2.4, 2.2),\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        transforms.CenterSpatialCropd(keys=[\"image\"], roi_size=(96, 96, 64)),\n",
    "        transforms.ScaleIntensityRangePercentilesd(keys=\"image\", lower=0, upper=99.5, b_min=0, b_max=1),\n",
    "    ]\n",
    ")\n",
    "train_ds = DecathlonDataset(\n",
    "    root_dir=root_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    section=\"training\",\n",
    "    cache_rate=1.0,\n",
    "    num_workers=4,\n",
    "    download=False,\n",
    "    seed=0,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "print(f'Image shape {train_ds[0][\"image\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a46a9",
   "metadata": {},
   "source": [
    "## Visualise examples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = first(train_loader)\n",
    "idx = 0\n",
    "\n",
    "img = check_data[\"image\"][idx, channel]\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "for ax in axs:\n",
    "    ax.axis(\"off\")\n",
    "ax = axs[0]\n",
    "ax.imshow(img[..., img.shape[2] // 2].rot90(), cmap=\"gray\")\n",
    "ax = axs[1]\n",
    "ax.imshow(img[:, img.shape[1] // 2, ...].rot90(), cmap=\"gray\")\n",
    "ax = axs[2]\n",
    "ax.imshow(img[img.shape[0] // 2, ...].rot90(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e37b5",
   "metadata": {},
   "source": [
    "## Download the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.Lambdad(keys=\"image\", func=lambda x: x[channel, :, :, :]),\n",
    "        transforms.AddChanneld(keys=[\"image\"]),\n",
    "        transforms.EnsureTyped(keys=[\"image\"]),\n",
    "        transforms.Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        transforms.Spacingd(\n",
    "            keys=[\"image\"],\n",
    "            pixdim=(2.4, 2.4, 2.2),\n",
    "            mode=(\"bilinear\"),\n",
    "        ),\n",
    "        transforms.CenterSpatialCropd(keys=[\"image\"], roi_size=(96, 96, 64)),\n",
    "        transforms.ScaleIntensityRangePercentilesd(keys=\"image\", lower=0, upper=99.5, b_min=0, b_max=1),\n",
    "    ]\n",
    ")\n",
    "val_ds = DecathlonDataset(\n",
    "    root_dir=root_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    section=\"validation\",\n",
    "    cache_rate=1.0,  # you may need a few Gb of RAM... Set to 0 otherwise\n",
    "    num_workers=4,\n",
    "    download=True,\n",
    "    seed=0,\n",
    "    transform=val_transforms,\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "print(f'Image shape {val_ds[0][\"image\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19532ecb",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0514e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "model = AutoencoderKL(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_channels=32,\n",
    "    latent_channels=3,\n",
    "    ch_mult=(1, 2, 2),\n",
    "    num_res_blocks=1,\n",
    "    norm_num_groups=16,\n",
    "    attention_levels=(False, False, True),\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "discriminator = PatchDiscriminator(\n",
    "    spatial_dims=3,\n",
    "    num_layers_d=3,\n",
    "    num_channels=32,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=4,\n",
    "    activation=(Act.LEAKYRELU, {\"negative_slope\": 0.2}),\n",
    "    norm=\"BATCH\",\n",
    "    bias=False,\n",
    "    padding=1,\n",
    ")\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptual_loss = PerceptualLoss(spatial_dims=3, network_type=\"squeeze\", fake_3d_ratio=0.25)\n",
    "perceptual_loss.to(device)\n",
    "\n",
    "adv_loss = PatchAdversarialLoss(criterion=\"least_squares\")\n",
    "adv_weight = 0.01\n",
    "perceptual_weight = 0.001\n",
    "\n",
    "optimizer_g = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_g = torch.cuda.amp.GradScaler()\n",
    "scaler_d = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19616e",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98bfa9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "kl_weight = 1e-6\n",
    "n_epochs = 30\n",
    "val_interval = 6\n",
    "epoch_recon_loss_list = []\n",
    "epoch_gen_loss_list = []\n",
    "epoch_disc_loss_list = []\n",
    "val_recon_epoch_loss_list = []\n",
    "intermediary_images = []\n",
    "n_example_images = 4\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    discriminator.train()\n",
    "    epoch_loss = 0\n",
    "    gen_epoch_loss = 0\n",
    "    disc_epoch_loss = 0\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), ncols=110)\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for step, batch in progress_bar:\n",
    "        # select only one channel from the Decathlon dataset\n",
    "        images = batch[\"image\"].to(device)\n",
    "        optimizer_g.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Generator part\n",
    "        with autocast(enabled=True):\n",
    "            reconstruction, z_mu, z_sigma = model(images)\n",
    "            logits_fake = discriminator(reconstruction.contiguous().float())[-1]\n",
    "\n",
    "            recons_loss = F.l1_loss(reconstruction.float(), images.float())\n",
    "            p_loss = perceptual_loss(reconstruction.float(), images.float())\n",
    "            generator_loss = adv_loss(logits_fake, target_is_real=True, for_discriminator=False)\n",
    "\n",
    "            kl_loss = 0.5 * torch.sum(z_mu.pow(2) + z_sigma.pow(2) - torch.log(z_sigma.pow(2)) - 1, dim=[1, 2, 3, 4])\n",
    "            kl_loss = torch.sum(kl_loss) / kl_loss.shape[0]\n",
    "\n",
    "            loss_g = recons_loss + (kl_weight * kl_loss) + (perceptual_weight * p_loss) + (adv_weight * generator_loss)\n",
    "\n",
    "        scaler_g.scale(loss_g).backward()\n",
    "        scaler_g.step(optimizer_g)\n",
    "        scaler_g.update()\n",
    "\n",
    "        # Discriminator part\n",
    "        with autocast(enabled=True):\n",
    "            optimizer_d.zero_grad(set_to_none=True)\n",
    "            logits_fake = discriminator(reconstruction.contiguous().detach())[-1]\n",
    "            loss_d_fake = adv_loss(logits_fake, target_is_real=False, for_discriminator=True)\n",
    "            logits_real = discriminator(images.contiguous().detach())[-1]\n",
    "            loss_d_real = adv_loss(logits_real, target_is_real=True, for_discriminator=True)\n",
    "            discriminator_loss = (loss_d_fake + loss_d_real) * 0.5\n",
    "\n",
    "            loss_d = adv_weight * discriminator_loss\n",
    "\n",
    "        scaler_d.scale(loss_d).backward()\n",
    "        scaler_d.step(optimizer_d)\n",
    "        scaler_d.update()\n",
    "\n",
    "        epoch_loss += recons_loss.item()\n",
    "        gen_epoch_loss += generator_loss.item()\n",
    "        disc_epoch_loss += discriminator_loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"recons_loss\": epoch_loss / (step + 1),\n",
    "                \"gen_loss\": gen_epoch_loss / (step + 1),\n",
    "                \"disc_loss\": disc_epoch_loss / (step + 1),\n",
    "            }\n",
    "        )\n",
    "    epoch_recon_loss_list.append(epoch_loss / (step + 1))\n",
    "    epoch_gen_loss_list.append(gen_epoch_loss / (step + 1))\n",
    "    epoch_disc_loss_list.append(disc_epoch_loss / (step + 1))\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_step, batch in enumerate(val_loader, start=1):\n",
    "                # select only one channel from the Decathlon dataset\n",
    "                images = batch[\"image\"].to(device)\n",
    "                optimizer_g.zero_grad(set_to_none=True)\n",
    "\n",
    "                reconstruction, z_mu, z_sigma = model(images)\n",
    "                # get the first sammple from the first validation batch for visualisation\n",
    "                # purposes\n",
    "                if val_step == 1:\n",
    "                    intermediary_images.append(reconstruction[:n_example_images, 0])\n",
    "\n",
    "                recons_loss = F.l1(reconstruction.float(), images.float())\n",
    "\n",
    "                val_loss += recons_loss.item()\n",
    "\n",
    "        val_loss /= val_step\n",
    "        val_recon_epoch_loss_list.append(val_loss)\n",
    "\n",
    "        print(f\"epoch {epoch + 1} val loss: {val_loss:.4f}\")\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c94e3",
   "metadata": {},
   "source": [
    "## Evaluate the trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066417fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "val_samples = np.linspace(val_interval, n_epochs, int(n_epochs / val_interval))\n",
    "plt.plot(np.linspace(1, n_epochs, n_epochs), epoch_recon_loss_list, label=\"Train\")\n",
    "plt.plot(val_samples, val_recon_epoch_loss_list, label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Adversarial Training Curves\", fontsize=20)\n",
    "plt.plot(np.linspace(1, n_epochs, n_epochs), epoch_gen_loss_list, color=\"C0\", linewidth=2.0, label=\"Generator\")\n",
    "plt.plot(np.linspace(1, n_epochs, n_epochs), epoch_disc_loss_list, color=\"C1\", linewidth=2.0, label=\"Discriminator\")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.xlabel(\"Epochs\", fontsize=16)\n",
    "plt.ylabel(\"Loss\", fontsize=16)\n",
    "plt.legend(prop={\"size\": 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbecae",
   "metadata": {},
   "source": [
    "### Visualise some reconstruction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = check_data[\"image\"][idx, channel]\n",
    "fig, axs = plt.subplots(nrows=len(intermediary_images), ncols=3, constrained_layout=True, figsize=(8, 6))\n",
    "\n",
    "# Remove ticks\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for image_n in range(len(intermediary_images)):\n",
    "    axs[image_n, 0].imshow(intermediary_images[image_n][0, ..., img.shape[2] // 2].cpu(), cmap=\"gray\")\n",
    "    axs[image_n, 1].imshow(intermediary_images[image_n][0, :, img.shape[1] // 2, ...].cpu().rot90(), cmap=\"gray\")\n",
    "    axs[image_n, 2].imshow(intermediary_images[image_n][0, img.shape[0] // 2, ...].cpu().rot90(), cmap=\"gray\")\n",
    "    axs[image_n, 0].set_ylabel(f\"Epoch {val_samples[image_n]:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].imshow(images[0, 0, ..., img.shape[2] // 2].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].title.set_text(\"Inputted Image\")\n",
    "ax[1].imshow(reconstruction[0, 0, ..., img.shape[2] // 2].detach().cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].title.set_text(\"Reconstruction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292506bf",
   "metadata": {},
   "source": [
    "## Clean up data directory\n",
    "\n",
    "Remove directory if a temporary storage was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25551b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

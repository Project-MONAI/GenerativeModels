{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a3f076",
   "metadata": {},
   "source": [
    "# 3D Latent Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5355ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add buttom with \"Open with Colab\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbb4a3",
   "metadata": {},
   "source": [
    "## Set up environment using Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caae787",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e6b23",
   "metadata": {},
   "source": [
    "## Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44c4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.utils import first, set_determinism\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generative.networks.nets import AutoencoderKL, DiffusionModelUNet, LatentDiffusionModel\n",
    "from generative.schedulers import DDPMScheduler\n",
    "from generative.losses import perceptual, adversarial_loss\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility purposes set a seed\n",
    "set_determinism(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b02aa6c",
   "metadata": {},
   "source": [
    "## Setup a data directory and download dataset\n",
    "Specify a MONAI_DATA_DIRECTORY variable, where the data will be downloaded. If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d450e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "root_dir = \"./\"\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74302407",
   "metadata": {},
   "source": [
    "## Download the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0 # 0 = Flair\n",
    "assert channel in [0,1,2,3], 'Choose a valid channel'\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.EnsureTyped(keys=[\"image\"]),\n",
    "        transforms.Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        transforms.Spacingd(keys=[\"image\"], pixdim=(3.0, 3.0, 2.2), mode=(\"bilinear\"),),\n",
    "        transforms.CenterSpatialCropd(keys=[\"image\"],roi_size = (120,120,64)),\n",
    "        transforms.ScaleIntensityRangePercentilesd(keys=\"image\", lower= 0, upper= 99.5, b_min= 0, b_max= 1),\n",
    "    ]\n",
    ")\n",
    "train_ds = DecathlonDataset(root_dir=root_dir, task = 'Task01_BrainTumour', section=\"training\", \n",
    "                            cache_rate=1.0, # you may need a few Gb of RAM... Set to 0 otherwise\n",
    "                            num_workers=4,\n",
    "                            download=False, # Set download to True if the dataset hasnt been downloaded yet\n",
    "                            seed=0, transform = train_transforms) \n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "print(f'Image shape {train_ds[0][\"image\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36e0c4",
   "metadata": {},
   "source": [
    "## Visualise examples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot axial, coronal and sagittal slices of a training sample\n",
    "check_data = first(train_loader)\n",
    "idx = 0\n",
    "\n",
    "img = check_data[\"image\"][idx, channel]\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "for ax in axs:\n",
    "    ax.axis(\"off\")\n",
    "ax = axs[0]\n",
    "ax.imshow(img[...,img.shape[2]//2], cmap=\"gray\")\n",
    "ax = axs[1]\n",
    "ax.imshow(img[:,img.shape[1]//2, ...], cmap=\"gray\")\n",
    "ax = axs[2]\n",
    "ax.imshow(img[img.shape[0]//2, ...], cmap=\"gray\")\n",
    "plt.savefig(\"training_examples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbf127",
   "metadata": {},
   "source": [
    "## Download the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d9b41a",
   "metadata": {},
   "source": [
    "val_data = MedNISTDataset(root_dir=root_dir, section=\"validation\", download=True, seed=0)\n",
    "val_datalist = [{\"image\": item[\"image\"]} for item in train_data.data if item[\"class_name\"] == \"Hand\"]\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ]\n",
    ")\n",
    "val_ds = Dataset(data=val_datalist, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d7eee",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_model = AutoencoderKL(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_channels=32,\n",
    "    latent_channels=3,\n",
    "    ch_mult=(1, 2, 2),\n",
    "    num_res_blocks=1,\n",
    "    norm_num_groups=16,\n",
    "    attention_levels=(False, False, True),\n",
    ")\n",
    "\n",
    "unet = DiffusionModelUNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    num_res_blocks=1,\n",
    "    attention_resolutions=[4, 2],\n",
    "    channel_mult=[1, 2, 2],\n",
    "    model_channels=64,\n",
    "    # TODO: play with this number\n",
    "    num_heads=1,\n",
    ")\n",
    "\n",
    "scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_schedule=\"linear\",\n",
    "    beta_start=0.0015,\n",
    "    beta_end=0.0195,\n",
    ")\n",
    "\n",
    "model = LatentDiffusionModel(first_stage=stage1_model, unet_network=unet, scheduler=scheduler)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_perceptual = perceptual.PerceptualLoss(spatial_dims = 3, network_type = 'squeeze', is_fake_3d = True, fake_3d_ratio= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fe2d4",
   "metadata": {},
   "source": [
    "## Train AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa225d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 2.5e-5)\n",
    "kl_weight = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add lr_scheduler with warm-up\n",
    "# TODO: Add EMA model\n",
    "\n",
    "n_epochs = 1\n",
    "val_interval = 2\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for step, batch in progress_bar:\n",
    "        images = batch[\"image\"][:,[channel],...].to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        reconstruction, z_mu, z_sigma = model.first_stage(images)\n",
    "\n",
    "        l1_loss = F.l1_loss(reconstruction.float(), images.float())\n",
    "        perceptual_loss = loss_perceptual(reconstruction.float(), images.float())\n",
    "\n",
    "        kl_loss = 0.5 * torch.sum(z_mu.pow(2) + z_sigma.pow(2) - torch.log(z_sigma.pow(2)) - 1, dim = [1, 2, 3, 4])\n",
    "        kl_loss = torch.sum(kl_loss) / kl_loss.shape[0]\n",
    "        # TODO : adverarial loss\n",
    "        #\n",
    "        loss = l1_loss + perceptual_loss + kl_weight * kl_loss        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": epoch_loss / (step + 1),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e38b28",
   "metadata": {},
   "source": [
    "### Visualise reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9685bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot axial, coronal and sagittal slices of a training sample\n",
    "idx = 0\n",
    "img = reconstruction[idx, channel].detach().cpu().numpy()\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "for ax in axs:\n",
    "    ax.axis(\"off\")\n",
    "ax = axs[0]\n",
    "ax.imshow(img[...,img.shape[2]//2], cmap=\"gray\")\n",
    "ax = axs[1]\n",
    "ax.imshow(img[:,img.shape[1]//2, ...], cmap=\"gray\")\n",
    "ax = axs[2]\n",
    "ax.imshow(img[img.shape[0]//2, ...], cmap=\"gray\")\n",
    "plt.savefig(\"reconstruction_examples.png\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('torch_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7e6f8385898884a13cbe220eefefb32cba5012927a94186742ddc14746e4dba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

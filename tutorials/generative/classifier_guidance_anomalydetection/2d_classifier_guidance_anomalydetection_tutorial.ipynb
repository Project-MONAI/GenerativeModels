{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d95da6",
   "metadata": {},
   "source": [
    "# Anomaly Detection with classifier guidance\n",
    "\n",
    "This tutorial illustrates how to use MONAI for training a 2D gradient-guided anomaly detection using DDIMs [1].\n",
    "\n",
    "\n",
    "[1] - Wolleb et al. \"Diffusion Models for Medical Anomaly Detection\" https://arxiv.org/abs/2203.04306\n",
    "\n",
    "\n",
    "TODO: Add Open in Colab\n",
    "\n",
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f2d5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "/home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing generative.egg-info/PKG-INFO\n",
      "writing dependency_links to generative.egg-info/dependency_links.txt\n",
      "writing requirements to generative.egg-info/requires.txt\n",
      "writing top-level names to generative.egg-info/top_level.txt\n",
      "reading manifest file 'generative.egg-info/SOURCES.txt'\n",
      "writing manifest file 'generative.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
      "\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying generative.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying generative.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying generative.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying generative.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying generative.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/generative-0.1.0-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing generative-0.1.0-py3.10.egg\n",
      "Removing /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages/generative-0.1.0-py3.10.egg\n",
      "Copying generative-0.1.0-py3.10.egg to /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "generative 0.1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages/generative-0.1.0-py3.10.egg\n",
      "Processing dependencies for generative==0.1.0\n",
      "Searching for lpips==0.1.4\n",
      "Best match: lpips 0.1.4\n",
      "Processing lpips-0.1.4-py3.10.egg\n",
      "lpips 0.1.4 is already the active version in easy-install.pth\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages/lpips-0.1.4-py3.10.egg\n",
      "Searching for tqdm==4.64.1\n",
      "Best match: tqdm 4.64.1\n",
      "Processing tqdm-4.64.1-py3.10.egg\n",
      "tqdm 4.64.1 is already the active version in easy-install.pth\n",
      "Installing tqdm script to /home/juliawolleb/anaconda3/envs/experiment/bin\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages/tqdm-4.64.1-py3.10.egg\n",
      "Searching for scipy==1.9.0\n",
      "Best match: scipy 1.9.0\n",
      "Adding scipy 1.9.0 to easy-install.pth file\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for numpy==1.23.2\n",
      "Best match: numpy 1.23.2\n",
      "Adding numpy 1.23.2 to easy-install.pth file\n",
      "Installing f2py script to /home/juliawolleb/anaconda3/envs/experiment/bin\n",
      "Installing f2py3 script to /home/juliawolleb/anaconda3/envs/experiment/bin\n",
      "Installing f2py3.10 script to /home/juliawolleb/anaconda3/envs/experiment/bin\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for torchvision==0.13.1\n",
      "Best match: torchvision 0.13.1\n",
      "Adding torchvision 0.13.1 to easy-install.pth file\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for torch==1.12.1\n",
      "Best match: torch 1.12.1\n",
      "Adding torch 1.12.1 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /home/juliawolleb/anaconda3/envs/experiment/bin\n",
      "Installing convert-onnx-to-caffe2 script to /home/juliawolleb/anaconda3/envs/experiment/bin\n",
      "Installing torchrun script to /home/juliawolleb/anaconda3/envs/experiment/bin\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for Pillow==9.2.0\n",
      "Best match: Pillow 9.2.0\n",
      "Adding Pillow 9.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for requests==2.28.1\n",
      "Best match: requests 2.28.1\n",
      "Adding requests 2.28.1 to easy-install.pth file\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for typing-extensions==4.3.0\n",
      "Best match: typing-extensions 4.3.0\n",
      "Adding typing-extensions 4.3.0 to easy-install.pth file\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for certifi==2022.6.15\n",
      "Best match: certifi 2022.6.15\n",
      "Adding certifi 2022.6.15 to easy-install.pth file\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for urllib3==1.26.11\n",
      "Best match: urllib3 1.26.11\n",
      "Adding urllib3 1.26.11 to easy-install.pth file\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for idna==3.3\n",
      "Best match: idna 3.3\n",
      "Adding idna 3.3 to easy-install.pth file\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Searching for charset-normalizer==2.1.1\n",
      "Best match: charset-normalizer 2.1.1\n",
      "Adding charset-normalizer 2.1.1 to easy-install.pth file\n",
      "Installing normalizer script to /home/juliawolleb/anaconda3/envs/experiment/bin\n",
      "\n",
      "Using /home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages\n",
      "Finished processing dependencies for generative==0.1.0\n"
     ]
    }
   ],
   "source": [
    "!python /home/juliawolleb/PycharmProjects/MONAI/GenerativeModels/setup.py install\n",
    "!python -c \"import monai\" || pip install -q \"monai-weekly[pillow, tqdm, einops]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "!python -c \"import seaborn\" || pip install -q seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b766027",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972ed3f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ZipImportError",
     "evalue": "bad local file header: '/home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages/generative-0.1.0-py3.10.egg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZipImportError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradScaler, autocast\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenerative\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minferers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiffusionInferer\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# TODO: Add right import reference after deployed\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenerative\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiffusion_model_unet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiffusionModelUNet, DiffusionModelEncoder\n",
      "File \u001b[0;32m<frozen zipimport>:196\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen zipimport>:752\u001b[0m, in \u001b[0;36m_get_module_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen zipimport>:598\u001b[0m, in \u001b[0;36m_get_data\u001b[0;34m(archive, toc_entry)\u001b[0m\n",
      "\u001b[0;31mZipImportError\u001b[0m: bad local file header: '/home/juliawolleb/anaconda3/envs/experiment/lib/python3.10/site-packages/generative-0.1.0-py3.10.egg'"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms\n",
    "from monai.apps import MedNISTDataset, DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.utils import first, set_determinism\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generative.inferers import DiffusionInferer\n",
    "\n",
    "# TODO: Add right import reference after deployed\n",
    "from generative.networks.nets.diffusion_model_unet import DiffusionModelUNet, DiffusionModelEncoder\n",
    "\n",
    "from generative.networks.schedulers.ddpm import DDPMScheduler\n",
    "from generative.networks.schedulers.ddim import DDIMScheduler\n",
    "print_config()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ff515",
   "metadata": {},
   "source": [
    "## Setup data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b4323e7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/juliawolleb/PycharmProjects/MONAI/data_brats\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "#root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "root_dir='/home/juliawolleb/PycharmProjects/MONAI/data_brats'\n",
    "\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99175d50",
   "metadata": {},
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34ea510f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "set_determinism(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac55e9d",
   "metadata": {},
   "source": [
    "## Setup BRATS Dataset for 2D slices  and training and validation dataloaders\n",
    "As baseline, we use the load_2d_brats.ipynb written by Pedro in issue 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1927b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task01_BrainTumour.tar:  71%|█████████▉    | 5.03G/7.09G [04:43<01:46, 20.8MB/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 2\n",
    "channel = 0  # 0 = Flair\n",
    "assert channel in [0, 1, 2, 3], \"Choose a valid channel\"\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\",\"label\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n",
    "        transforms.Lambdad(keys=[\"image\"], func=lambda x: x[channel, :, :, :]),\n",
    "        transforms.AddChanneld(keys=[\"image\"]),\n",
    "        transforms.EnsureTyped(keys=[\"image\",\"label\"]),\n",
    "        transforms.Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n",
    "        transforms.Spacingd(\n",
    "            keys=[\"image\",\"label\"],\n",
    "            pixdim=(3.0, 3.0, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        transforms.CenterSpatialCropd(keys=[\"image\",\"label\"], roi_size=(64, 64, 64)),\n",
    "        transforms.ScaleIntensityRangePercentilesd(keys=\"image\", lower=0, upper=99.5, b_min=0, b_max=1),\n",
    "        transforms.CopyItemsd(keys=[\"label\"], times=1, names=[\"slice_label\"]),\n",
    "        transforms.Lambdad(keys=[\"slice_label\"], func=lambda x: (x.reshape(x.shape[0], -1, x.shape[-1]).sum(1) > 0 ).float().squeeze()),\n",
    "    ]\n",
    ")\n",
    "train_ds = DecathlonDataset(\n",
    "    root_dir=root_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    section=\"training\",  # validation\n",
    "    cache_rate=0.0,  # you may need a few Gb of RAM... Set to 0 otherwise\n",
    "    num_workers=4,\n",
    "    download=True,  # Set download to True if the dataset hasnt been downloaded yet\n",
    "    seed=0,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "nb_3D_images_to_mix = 2\n",
    "train_loader_3D = DataLoader(train_ds, batch_size=nb_3D_images_to_mix, shuffle=True, num_workers=4)\n",
    "print(f'Image shape {train_ds[0][\"image\"].shape}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d72110-a8b3-4e03-91cc-1dab4d5a7b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-02 10:39:45,467 - INFO - Verified 'Task01_BrainTumour.tar', md5: 240a19d752f0d9e9101544901065d872.\n",
      "2023-02-02 10:39:45,469 - INFO - File exists: /tmp/tmpyurp7egh/Task01_BrainTumour.tar, skipped downloading.\n",
      "2023-02-02 10:39:45,471 - INFO - Non-empty folder exists in /tmp/tmpyurp7egh/Task01_BrainTumour, skipped extracting.\n",
      "Image shape torch.Size([1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_ds = DecathlonDataset(\n",
    "    root_dir=root_dir,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    section=\"validation\",  # validation\n",
    "    cache_rate=0.0,  # you may need a few Gb of RAM... Set to 0 otherwise\n",
    "    num_workers=4,\n",
    "    download=True,  # Set download to True if the dataset hasnt been downloaded yet\n",
    "    seed=0,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "val_loader_3D = DataLoader(val_ds, batch_size=nb_3D_images_to_mix, shuffle=True, num_workers=4)\n",
    "print(f'Image shape {val_ds[0][\"image\"].shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986f55c",
   "metadata": {},
   "source": [
    "Here we use transforms to augment the training dataset, as usual:\n",
    "\n",
    "1. `LoadImaged` loads the hands images from files.\n",
    "1. `EnsureChannelFirstd` ensures the original data to construct \"channel first\" shape.\n",
    "1. `ScaleIntensityRanged` extracts intensity range [0, 255] and scales to [0, 1].\n",
    "1. `RandAffined` efficiently performs rotate, scale, shear, translate, etc. together based on PyTorch affine transform.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f108ebb",
   "metadata": {},
   "source": [
    "### Visualisation of the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4105a01f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([128, 1, 64, 64])\n",
      "Slices class: tensor([0., 0., 0., 1.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from typing import Dict\n",
    "def get_batched_2d_axial_slices(data : Dict):\n",
    "    images_3D = data['image']\n",
    "    batched_2d_slices = torch.cat(images_3D.split(1, dim = -1), 0).squeeze(-1) # images_3D.view(images_3D.shape[0]*images_3D.shape[-1],*images_3D.shape[1:-1])\n",
    "    slice_label = data['slice_label']\n",
    "    #slice_label = (mask_label.reshape(mask_label.shape[0], -1, mask_label.shape[-1]).sum(1) > 0 ).float()\n",
    "    slice_label = torch.cat(slice_label.split(1, dim = -1),0).squeeze()\n",
    "    return batched_2d_slices, slice_label\n",
    "\n",
    "check_data = first(train_loader_3D)\n",
    "batched_2d_slices, slice_label = get_batched_2d_axial_slices(check_data)\n",
    "idx = list(torch.randperm(batched_2d_slices.shape[0]))\n",
    "slices = [0,30,45,63]\n",
    "print(f\"Batch shape: {batched_2d_slices.shape}\")\n",
    "print(f\"Slices class: {slice_label[idx][slices].view(-1)}\")\n",
    "image_visualisation = torch.cat(batched_2d_slices[idx][slices].squeeze().split(1), dim=2).squeeze()\n",
    "plt.figure(\"training images\", (12, 6))\n",
    "plt.imshow(image_visualisation, vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4249e4be-f7e7-48e9-9aa9-436da8c1d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 64, 64]), torch.Size([2]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subset_2D = zip(batched_2d_slices.split(batch_size),slice_label.split(batch_size))#\n",
    "a,b = next(subset_2D)  #what is a, what is b? Are these the next images? \n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08428bc6",
   "metadata": {},
   "source": [
    "### Define network, scheduler, optimizer, and inferer\n",
    "At this step, we instantiate the MONAI components to create a DDPM, the UNET, the noise scheduler, and the inferer used for training and sampling. We are using\n",
    "the original DDPM scheduler containing 1000 timesteps in its Markov chain, and a 2D UNET with attention mechanisms\n",
    "in the 3rd level, each with 1 attention head (`num_head_channels=64`).\n",
    "\n",
    "In order to pass conditioning variables with dimension of 1 (just specifying the modality of the image), we use:\n",
    "\n",
    "`\n",
    "with_conditioning=True,\n",
    "cross_attention_dim=1,\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bee5913e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = DiffusionModelUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_channels=(64, 64, 64),\n",
    "    attention_levels=(False, False, True),\n",
    "    num_res_blocks=1,\n",
    "    num_head_channels=64,\n",
    "    with_conditioning=False,\n",
    "  #  cross_attention_dim=1,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2.5e-5)\n",
    "\n",
    "inferer = DiffusionInferer(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d3ab2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model training of the Diffusion Model\n",
    "Here, we are training our diffusion model for 75 epochs (training time: ~50 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c0ed909",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|            | 1/128 [00:00<00:16,  7.89it/s, loss=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 1 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▍               | 3/128 [00:00<00:13,  9.55it/s, loss=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 3 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 4 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5%|▋           | 7/128 [00:00<00:11, 10.26it/s, loss=0.992]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 6 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 7 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   7%|▊           | 9/128 [00:00<00:11, 10.38it/s, loss=0.988]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 9 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 10 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|█          | 13/128 [00:01<00:10, 10.52it/s, loss=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 12 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 13 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  12%|█▎         | 15/128 [00:01<00:10, 10.51it/s, loss=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n",
      "step 15 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n",
      "step 16 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  15%|█▋         | 19/128 [00:01<00:10, 10.65it/s, loss=0.971]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n",
      "step 18 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n",
      "step 19 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  16%|█▊         | 21/128 [00:02<00:10, 10.22it/s, loss=0.968]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n",
      "step 21 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|█▉         | 23/128 [00:02<00:10,  9.82it/s, loss=0.964]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n",
      "step 23 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  20%|██▏        | 25/128 [00:02<00:10,  9.50it/s, loss=0.961]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n",
      "step 25 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  21%|██▎        | 27/128 [00:02<00:10,  9.34it/s, loss=0.956]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([1., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([1., 1.], device='cuda:0')\n",
      "step 27 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 1.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  23%|██▍        | 29/128 [00:02<00:10,  9.18it/s, loss=0.953]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 28 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 29 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  24%|██▋        | 31/128 [00:03<00:10,  9.21it/s, loss=0.949]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 31 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  26%|██▊        | 33/128 [00:03<00:10,  9.20it/s, loss=0.944]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 33 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  27%|███▎        | 35/128 [00:03<00:10,  9.12it/s, loss=0.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 34 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 35 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  29%|███▏       | 37/128 [00:03<00:10,  9.07it/s, loss=0.934]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 36 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 37 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  30%|███▎       | 39/128 [00:04<00:09,  9.09it/s, loss=0.929]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 38 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 39 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  32%|███▌       | 41/128 [00:04<00:09,  9.15it/s, loss=0.925]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 41 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  34%|███▋       | 43/128 [00:04<00:09,  9.17it/s, loss=0.921]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 42 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 43 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  35%|███▊       | 45/128 [00:04<00:09,  9.15it/s, loss=0.916]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 45 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  37%|████       | 47/128 [00:04<00:09,  8.95it/s, loss=0.912]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 47 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  38%|████▏      | 49/128 [00:05<00:08,  9.00it/s, loss=0.906]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 49 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  40%|████▍      | 51/128 [00:05<00:08,  9.08it/s, loss=0.904]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 51 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  41%|████▌      | 53/128 [00:05<00:08,  9.06it/s, loss=0.899]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 52 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 53 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  43%|████▋      | 55/128 [00:05<00:07,  9.18it/s, loss=0.894]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 54 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 55 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  45%|████▉      | 57/128 [00:05<00:07,  9.18it/s, loss=0.889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 56 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 57 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  46%|█████      | 59/128 [00:06<00:07,  9.22it/s, loss=0.884]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 58 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 59 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  48%|█████▎     | 62/128 [00:06<00:06, 10.20it/s, loss=0.877]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 61 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n",
      "step 62 torch.Size([2, 1, 64, 64]) torch.Size([2]) tensor([0., 0.])\n",
      "image torch.Size([2, 1, 64, 64])\n",
      "classes tensor([0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  49%|█████▍     | 63/128 [00:06<00:06,  9.58it/s, loss=0.874]\n",
      "Epoch 1:   0%|                                | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed, total time: 6.586989164352417.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "val_interval = 5\n",
    "epoch_loss_list = []\n",
    "val_epoch_loss_list = []\n",
    "\n",
    "\n",
    "scaler = GradScaler()\n",
    "total_start = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(enumerate(subset_2D), total=len(idx), ncols=70)\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for step, (a,b) in progress_bar:\n",
    "        print('step', step, a.shape, b.shape, b)\n",
    "       \n",
    "        images = a.to(device)\n",
    "        print('image', images.shape)\n",
    "        classes = b.to(device)\n",
    "        print('classes', classes)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        timesteps = torch.randint(0, 1000, (len(images),)).to(device)\n",
    "\n",
    "        with autocast(enabled=True):\n",
    "            # Generate random noise\n",
    "            noise = torch.randn_like(images).to(device)\n",
    "\n",
    "            # Get model prediction\n",
    "            noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps)  #remove the class conditioning\n",
    "\n",
    "            loss = F.mse_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": epoch_loss / (step + 1),\n",
    "            }\n",
    "        )\n",
    "    epoch_loss_list.append(epoch_loss / (step + 1))\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        for step, batch in enumerate(val_loader):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            classes = batch[\"class\"].to(device)\n",
    "            timesteps = torch.randint(0, 1000, (len(images),)).to(device)#torch.from_numpy(np.arange(0, 1000)[::-1].copy())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with autocast(enabled=True):\n",
    "                    noise = torch.randn_like(images).to(device)\n",
    "                    noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps)\n",
    "                    val_loss = F.mse_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"val_loss\": val_epoch_loss / (step + 1),\n",
    "                }\n",
    "            )\n",
    "        val_epoch_loss_list.append(val_epoch_loss / (step + 1))\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"train completed, total time: {total_time}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f4dbbf2-31af-4204-b1ea-d9d57491278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model training of the Classification Model\n",
    "#Here, we are training our binary classification model for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a99c3966-6ac0-431f-8d2e-2bbea44e991d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## First, we define the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44cc6928-2525-4e61-8805-15b409097bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionModelEncoder(\n",
       "  (conv_in): Convolution(\n",
       "    (conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (downsampler): Downsample(\n",
       "        (op): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DownBlock(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "      (downsampler): Downsample(\n",
       "        (op): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): AttnDownBlock(\n",
       "      (attentions): ModuleList(\n",
       "        (0): AttentionBlock(\n",
       "          (norm): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_attn): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): AttnMidBlock(\n",
       "    (resnet_1): ResnetBlock(\n",
       "      (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "      (nonlinearity): SiLU()\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (attention): AttentionBlock(\n",
       "      (norm): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "      (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_attn): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (resnet_2): ResnetBlock(\n",
       "      (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "      (nonlinearity): SiLU()\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): AttnUpBlock(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (attentions): ModuleList(\n",
       "        (0): AttentionBlock(\n",
       "          (norm): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_attn): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_attn): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (upsampler): Upsample(\n",
       "        (conv): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnUpBlock(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (attentions): ModuleList(\n",
       "        (0): AttentionBlock(\n",
       "          (norm): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_attn): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_attn): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (upsampler): Upsample(\n",
       "        (conv): Convolution(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UpBlock(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv1): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (time_emb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
       "          (conv2): Convolution(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (skip_connection): Convolution(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=16384, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DiffusionModelEncoder(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_channels=(64, 64, 64),\n",
    "   # attention_levels=(False, False, True),\n",
    "    num_res_blocks=1,\n",
    "    num_head_channels=64,\n",
    "    with_conditioning=False,\n",
    "  #  cross_attention_dim=1,\n",
    ")\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de18d5cb-68e7-407c-afe9-8efd7a5a904a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "batch_size=6\n",
    "subset2_2D = zip(batched_2d_slices.split(batch_size),slice_label.split(batch_size))#\n",
    "subset3_2D = zip(batched_2d_slices.split(batch_size),slice_label.split(batch_size))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7803890-5504-475d-8dd7-c87cae4a1b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▊                       | 4/128 [00:00<00:03, 33.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7719, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7611, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7668, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7561, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7131, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.6271, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.6277, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.6392, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9%|██▏                    | 12/128 [00:00<00:03, 35.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.6372, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7021, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7493, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7826, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7407, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7278, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7590, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7495, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  17%|███▉                   | 22/128 [00:00<00:03, 35.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7754, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7786, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7738, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7787, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "loss tensor(0.7888, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "h torch.Size([2, 64, 16, 16]) 2\n",
      "h torch.Size([2, 16384])\n",
      "loss tensor(0.7906, device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 2:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 3:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 4:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 4:  17%|███▊                  | 22/128 [00:00<00:00, 110.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([6, 64, 16, 16]) 6\n",
      "h torch.Size([6, 16384])\n",
      "h torch.Size([2, 64, 16, 16]) 2\n",
      "h torch.Size([2, 16384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 6:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 7:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 8:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 9:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 9:   0%|                                | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 10:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 11:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 12:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 13:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 14:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 14:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 15:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 16:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 17:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 18:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 19:   0%|                               | 0/128 [00:00<?, ?it/s]\n",
      "Epoch 19:   0%|                               | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed, total time: 0.9466347694396973.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "val_interval = 5\n",
    "epoch_loss_list = []\n",
    "val_epoch_loss_list = []\n",
    "\n",
    "classifier.to(device)\n",
    "scaler = GradScaler()\n",
    "total_start = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    classifier.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar2 = tqdm(enumerate(subset2_2D), total=len(idx), ncols=70)\n",
    "    progress_bar2.set_description(f\"Epoch {epoch}\")\n",
    "    for step, (a,b) in progress_bar2:\n",
    "        images = a.to(device)\n",
    "        classes = b.to(device)  \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        timesteps = torch.randint(0, 1000, (len(images),)).to(device)\n",
    "\n",
    "        with autocast(enabled=True):\n",
    "            # Generate random noise\n",
    "            noise = 0*torch.randn_like(images).to(device)\n",
    "\n",
    "            # Get model prediction\n",
    "           \n",
    "            pred = inferer(inputs=images, diffusion_model=classifier, noise=noise, timesteps=timesteps)  #remove the class conditioning\n",
    "          #  noise_pred = inferer(inputs=images, diffusion_model=model, noise=noise, timesteps=timesteps)  #remove the class conditioning\n",
    "            loss = F.binary_cross_entropy_with_logits(pred[:,0].float(), classes.float())\n",
    "            print('loss', loss)\n",
    "        #scaler.scale(loss).backward()\n",
    "       # scaler.step(optimizer)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": epoch_loss / (step + 1),\n",
    "            }\n",
    "        )\n",
    "    epoch_loss_list.append(epoch_loss / (step + 1))\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        progress_bar3 = tqdm(enumerate(subset3_2D), total=len(idx), ncols=70)\n",
    "        progress_bar3.set_description(f\"Epoch {epoch}\")\n",
    "        for step, (a,b) in progress_bar3:\n",
    "            images = a.to(device)\n",
    "            classes = b.to(device)  \n",
    "       \n",
    "            timesteps = torch.randint(0, 1000, (len(images),)).to(device)#torch.from_numpy(np.arange(0, 1000)[::-1].copy())\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with autocast(enabled=True):\n",
    "                    noise = 0*torch.randn_like(images).to(device)\n",
    "                    pred = inferer(inputs=images, diffusion_model=classifier, noise=noise, timesteps=timesteps)\n",
    "                    val_loss = F.binary_cross_entropy_with_logits(pred[:,0].float(), classes.float())\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"val_loss\": val_epoch_loss / (step + 1),\n",
    "                }\n",
    "            )\n",
    "        val_epoch_loss_list.append(val_epoch_loss / (step + 1))\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"train completed, total time: {total_time}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676b3fe",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8385176",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseaborn-bright\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning Curves\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_loss_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m      5\u001b[0m     np\u001b[38;5;241m.\u001b[39mlinspace(val_interval, n_epochs, \u001b[38;5;28mint\u001b[39m(n_epochs \u001b[38;5;241m/\u001b[39m val_interval)),\n\u001b[1;32m      6\u001b[0m     val_epoch_loss_list,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks(fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment/lib/python3.10/site-packages/matplotlib/pyplot.py:2767\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2768\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2769\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1635\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1635\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment/lib/python3.10/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/experiment/lib/python3.10/site-packages/matplotlib/axes/_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (5,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"seaborn-bright\")\n",
    "plt.title(\"Learning Curves\", fontsize=20)\n",
    "plt.plot(np.linspace(1, n_epochs, n_epochs), epoch_loss_list, color=\"C0\", linewidth=2.0, label=\"Train\")\n",
    "plt.plot(\n",
    "    np.linspace(val_interval, n_epochs, int(n_epochs / val_interval)),\n",
    "    val_epoch_loss_list,\n",
    "    color=\"C1\",\n",
    "    linewidth=2.0,\n",
    "    label=\"Validation\",\n",
    ")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.xlabel(\"Epochs\", fontsize=16)\n",
    "plt.ylabel(\"Loss\", fontsize=16)\n",
    "plt.legend(prop={\"size\": 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd48c2d",
   "metadata": {},
   "source": [
    "### Sampling process with classifier-free guidance\n",
    "In order to sample using classifier-free guidance, for each step of the process we need to have 2 elements, one generated conditioned in the desired class (here we want to condition on Hands `=1`) and one using the unconditional class (`=-1`).\n",
    "Instead using directly the predicted class in every step, we use the unconditional plus the direction vector pointing to the condition that we want (`noise_pred_text - noise_pred_uncond`). The effect of the condition is defined by the `guidance_scale` defining the influence of our direction vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f71e4924",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:12<00:00, 77.06it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "guidance_scale = 7.0\n",
    "conditioning = torch.cat([-1 * torch.ones(1, 1, 1).float(), torch.ones(1, 1, 1).float()], dim=0).to(device)\n",
    "\n",
    "noise = torch.randn((1, 1, 64, 64))\n",
    "noise = noise.to(device)\n",
    "scheduler.set_timesteps(num_inference_steps=1000)\n",
    "progress_bar = tqdm(scheduler.timesteps)\n",
    "for t in progress_bar:\n",
    "    with autocast(enabled=True):\n",
    "        with torch.no_grad():\n",
    "            noise_input = torch.cat([noise] * 2)\n",
    "            model_output = model(noise_input, timesteps=torch.Tensor((t,)).to(noise.device))\n",
    "            noise_pred_uncond, noise_pred_text = model_output.chunk(2)\n",
    "            noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "    noise, _ = scheduler.step(noise_pred, t, noise)\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(noise[0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483b097",
   "metadata": {},
   "source": [
    "### Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b00d4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

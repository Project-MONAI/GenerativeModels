{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a3f076",
   "metadata": {},
   "source": [
    "# 2D Latent Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5355ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add buttom with \"Open with Colab\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbb4a3",
   "metadata": {},
   "source": [
    "## Set up environment using Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caae787",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e6b23",
   "metadata": {},
   "source": [
    "## Set up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms\n",
    "from monai.apps import MedNISTDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.utils import first, set_determinism\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generative.networks.nets import AutoencoderKL, DiffusionModelUNet, LatentDiffusionModel\n",
    "from generative.schedulers import DDPMScheduler\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility purposes set a seed\n",
    "set_determinism(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b02aa6c",
   "metadata": {},
   "source": [
    "## Setup a data directory and download dataset\n",
    "Specify a MONAI_DATA_DIRECTORY variable, where the data will be downloaded. If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d450e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74302407",
   "metadata": {},
   "source": [
    "## Download the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MedNISTDataset(root_dir=root_dir, section=\"training\", download=True, seed=0)\n",
    "train_datalist = [{\"image\": item[\"image\"]} for item in train_data.data if item[\"class_name\"] == \"Hand\"]\n",
    "image_size = 64\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        # TODO: Change transformations\n",
    "        transforms.RandAffined(\n",
    "            keys=[\"image\"],\n",
    "            rotate_range=[(-np.pi / 36, np.pi / 36), (-np.pi / 36, np.pi / 36)],\n",
    "            translate_range=[(-1, 1), (-1, 1)],\n",
    "            scale_range=[(-0.05, 0.05), (-0.05, 0.05)],\n",
    "            spatial_size=[image_size, image_size],\n",
    "            padding_mode=\"zeros\",\n",
    "            prob=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "train_ds = Dataset(data=train_datalist, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36e0c4",
   "metadata": {},
   "source": [
    "## Visualise examples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3 examples from the training set\n",
    "check_data = first(train_loader)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "for image_n in range(3):\n",
    "    ax[image_n].imshow(check_data[\"image\"][image_n, 0, :, :], cmap=\"gray\")\n",
    "    ax[image_n].axis(\"off\")\n",
    "# TODO: remove path\n",
    "plt.savefig(\"/project/tutorials/generative/2d_ldm/hand_examples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbf127",
   "metadata": {},
   "source": [
    "## Download the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = MedNISTDataset(root_dir=root_dir, section=\"validation\", download=True, seed=0)\n",
    "val_datalist = [{\"image\": item[\"image\"]} for item in train_data.data if item[\"class_name\"] == \"Hand\"]\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ]\n",
    ")\n",
    "val_ds = Dataset(data=val_datalist, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d7eee",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_model = AutoencoderKL(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_channels=64,\n",
    "    latent_channels=8,\n",
    "    ch_mult=(1, 2, 3),\n",
    "    num_res_blocks=1,\n",
    "    norm_num_groups=16,\n",
    "    attention_levels=(False, False, True),\n",
    ")\n",
    "\n",
    "unet = DiffusionModelUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    num_res_blocks=1,\n",
    "    attention_resolutions=[4, 2],\n",
    "    channel_mult=[1, 2, 2],\n",
    "    model_channels=64,\n",
    "    # TODO: play with this number\n",
    "    num_heads=1,\n",
    ")\n",
    "\n",
    "scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_schedule=\"linear\",\n",
    "    beta_start=0.0015,\n",
    "    beta_end=0.0195,\n",
    ")\n",
    "\n",
    "model = LatentDiffusionModel(first_stage=stage1_model, unet_network=unet, scheduler=scheduler)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 2.5e-5)\n",
    "# TODO: Add lr_scheduler with warm-up\n",
    "# TODO: Add EMA model\n",
    "\n",
    "n_epochs = 20\n",
    "val_interval = 2\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for step, batch in progress_bar:\n",
    "        images = batch[\"image\"].to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # TODO: check how to deal with next commands with multi-GPU and for FL\n",
    "        with torch.no_grad():\n",
    "            clean_latent = model.first_stage(images)\n",
    "\n",
    "        timesteps = torch.randint(\n",
    "            0, model.scheduler.timesteps, (clean_latent.shape[0],), device=clean_latent.device\n",
    "        ).long()\n",
    "        noise = torch.randn_like(clean_latent).to(device)\n",
    "        noisy_latent = model.scheduler.q_sample(x_start=clean_latent, t=timesteps, noise=noise)\n",
    "        noise_pred = model.unet_network(noisy_latent, timesteps)\n",
    "\n",
    "        loss = F.l1_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": epoch_loss / (step + 1),\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af3a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
